dataset: mlp-classification
model: implicit

task:
  _target_: tasks.classification.ClassificationICL
  lr: 1e-4
  model:
    _target_: models.implicit.TransformerImplicit
    x_dim: 2
    y_dim: 2
    n_features: 256
    n_heads: 4
    n_hidden: 512
    n_layers: 8

data:
  _target_: data.classification.ClassificationDataModule
  kind: linear 
  x_dim: 2
  y_dim: 2
  kind_kwargs:
    hidden_dim: 64
    layers: 1
  min_context: 16
  max_context: 128
  batch_size: 128
  train_size: 1000
  val_size: 1000
  noise: 0.1
  context_style: "same"
  ood_styles: ["far", "wide"]

trainer:
  max_epochs: 1000

callbacks: