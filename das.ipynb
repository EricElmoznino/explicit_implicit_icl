{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "from einops import repeat\n",
    "import pyvene as pv\n",
    "import torch\n",
    "import wandb\n",
    "from tasks.regression import *\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    \"explicit-transformer\": \"1ejrnua7\",\n",
    "    \"explicit-mlp\": \"hb9li9ry\",\n",
    "    \"explicit-aux-transformer\": \"hzr77fqz\",\n",
    "    \"implicit\": \"huqr2bcp\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP = 'implicit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "run = api.run(f'leogagnon/Explicit-Implicit/runs/{experiments[EXP]}')\n",
    "artifact = api.artifact(f'leogagnon/Explicit-Implicit/model-{experiments[EXP]}:latest')\n",
    "path = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_module = RegressionICL.load_from_checkpoint(\n",
    "    checkpoint_path=os.path.join(path,'model.ckpt'),\n",
    "    strict=False,\n",
    "    model=hydra.utils.instantiate(run.config['model_config']),\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConfig(PretrainedConfig):\n",
    "    model_type = 'mymodel'\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "class MyModel(PreTrainedModel):\n",
    "    config_class = MyConfig\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        self.model = pl_module.model\n",
    "    def forward(self, x_c, y_c, x_q):\n",
    "        return self.model(x_c, y_c, x_q) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(2) for j in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model = MyModel(MyConfig())\n",
    "if EXP == \"implicit\":\n",
    "    pv_config = pv.IntervenableConfig(\n",
    "        representations=[\n",
    "            pv.RepresentationConfig(\n",
    "                component=f\"model.encoder.layers[{l}].output\",\n",
    "                intervention=pv.LowRankRotatedSpaceIntervention(\n",
    "                    embed_dim=256, low_rank_dimension=10, keep_last_dim=True\n",
    "                ),\n",
    "            )\n",
    "            for l in [2,3,5]\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    pv_config = pv.IntervenableConfig(\n",
    "        representations=pv.RepresentationConfig(\n",
    "            component=\"model.context_model.output\",\n",
    "            intervention=pv.LowRankRotatedSpaceIntervention(\n",
    "                embed_dim=256, low_rank_dimension=10\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "pv_model = pv.IntervenableModel(config=pv_config, model=hf_model)\n",
    "pv_model.set_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = hydra.utils.instantiate(run.config['experiment_config']['experiment']['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = {'iid': 0, 'far': 1, 'wide': 2}\n",
    "VAL_STYLE = 'wide'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 2.360770344734192\n",
      "Val loss : tensor(4.6505, device='cuda:0')\n",
      "Train loss : 0.5791825907570975\n",
      "Val loss : tensor(2.1302, device='cuda:0')\n",
      "Train loss : 0.2606759603534426\n",
      "Val loss : tensor(1.7268, device='cuda:0')\n",
      "Train loss : 0.14732533480439866\n",
      "Val loss : tensor(1.5393, device='cuda:0')\n",
      "Train loss : 0.10062737337180547\n",
      "Val loss : tensor(1.3253, device='cuda:0')\n",
      "Train loss : 0.07483400404453278\n",
      "Val loss : tensor(1.3590, device='cuda:0')\n",
      "Train loss : 0.06655098018901688\n",
      "Val loss : tensor(1.0370, device='cuda:0')\n",
      "Train loss : 0.04967491488371577\n",
      "Val loss : tensor(1.0519, device='cuda:0')\n",
      "Train loss : 0.051599811762571335\n",
      "Val loss : tensor(1.0727, device='cuda:0')\n",
      "Train loss : 0.03970677964389324\n",
      "Val loss : tensor(0.9081, device='cuda:0')\n",
      "Train loss : 0.03521640492337091\n",
      "Val loss : tensor(0.7734, device='cuda:0')\n",
      "Train loss : 0.026427481855664934\n",
      "Val loss : tensor(0.7373, device='cuda:0')\n",
      "Train loss : 0.027114037158233777\n",
      "Val loss : tensor(0.7432, device='cuda:0')\n",
      "Train loss : 0.026184880839926854\n",
      "Val loss : tensor(0.6253, device='cuda:0')\n",
      "Train loss : 0.02227629455072539\n",
      "Val loss : tensor(0.6676, device='cuda:0')\n",
      "Train loss : 0.019681723655334542\n",
      "Val loss : tensor(0.6734, device='cuda:0')\n",
      "Train loss : 0.0179298214082207\n",
      "Val loss : tensor(0.8093, device='cuda:0')\n",
      "Train loss : 0.01598755975386926\n",
      "Val loss : tensor(0.7265, device='cuda:0')\n",
      "Train loss : 0.01569007390311786\n",
      "Val loss : tensor(0.6715, device='cuda:0')\n",
      "Train loss : 0.015050479477005345\n",
      "Val loss : tensor(0.6834, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(pv_model.get_trainable_parameters())\n",
    "pv_model.model.eval()\n",
    "\n",
    "train_loss_traj = []\n",
    "val_loss_traj = []\n",
    "for epoch in range(20):\n",
    "    train_loss = []\n",
    "    for batch in datamodule.train_dataloader():\n",
    "        base = {\n",
    "            \"x_c\": batch[0][0].cuda(),\n",
    "            \"y_c\": batch[0][1].cuda(),\n",
    "            \"x_q\": batch[1][0].cuda(),\n",
    "        }\n",
    "        c_len = batch[0][0].shape[1]\n",
    "        bs = batch[0][0].shape[0]\n",
    "\n",
    "        # Different context, different queries, different latent\n",
    "        x_c_source, x_q_source = datamodule.train_data.sample_x(c_len)\n",
    "        w_source = datamodule.train_data.sample_function_params()\n",
    "        source = {\n",
    "            \"x_c\": x_c_source.cuda(),\n",
    "            \"y_c\": datamodule.train_data.function(x_c_source, w_source).cuda(),\n",
    "            \"x_q\": batch[1][0].cuda(),\n",
    "        }\n",
    "        loc = [[[[(c_len + i) for i in range(c_len)]] * bs] * 3] * 2\n",
    "        unit_locations = {\"sources->base\": loc} if EXP == \"implicit\" else None\n",
    "        y_q_intervened = pv_model(base, source, unit_locations=unit_locations)[1][0]\n",
    "        y_q_counterfactual = datamodule.train_data.function(\n",
    "            batch[1][0], w_source\n",
    "        ).cuda()\n",
    "\n",
    "        loss = torch.nn.functional.mse_loss(y_q_intervened, y_q_counterfactual)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += [loss.detach().cpu().item()]\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    train_loss_traj += [sum(train_loss) / len(train_loss)]\n",
    "    print(\"Train loss :\", train_loss_traj[-1])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in datamodule.val_dataloader()[val_idx[VAL_STYLE]]:\n",
    "            gc.collect()\n",
    "            base = {\n",
    "                \"x_c\": batch[0][0].cuda(),\n",
    "                \"y_c\": batch[0][1].cuda(),\n",
    "                \"x_q\": batch[1][0].cuda(),\n",
    "            }\n",
    "            c_len = batch[0][0].shape[1]\n",
    "            bs = batch[0][0].shape[0]\n",
    "\n",
    "            # Different context, different queries, different latent\n",
    "            x_c_source, x_q_source = datamodule.val_data[VAL_STYLE].sample_x(\n",
    "                batch[0][0].shape[1]\n",
    "            )\n",
    "            w_source = datamodule.val_data[VAL_STYLE].sample_function_params()\n",
    "            source = {\n",
    "                \"x_c\": x_c_source.cuda(),\n",
    "                \"y_c\": datamodule.val_data[VAL_STYLE]\n",
    "                .function(x_c_source, w_source)\n",
    "                .cuda(),\n",
    "                \"x_q\": batch[1][0].cuda(),\n",
    "            }\n",
    "\n",
    "            loc = [[[[(c_len + i) for i in range(c_len)]] * bs] * 3] * 2\n",
    "            unit_locations = {\"sources->base\": loc} if EXP == \"implicit\" else None\n",
    "            y_q_intervened = pv_model(base, source, unit_locations=unit_locations)[1][0]\n",
    "            y_q_counterfactual = (\n",
    "                datamodule.val_data[VAL_STYLE].function(batch[1][0], w_source).cuda()\n",
    "            )\n",
    "\n",
    "            loss = torch.nn.functional.mse_loss(y_q_intervened, y_q_counterfactual)\n",
    "            val_loss_traj += [loss.cpu().item()]\n",
    "            print(\"Val loss :\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit_mse = val_loss_traj[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "explicitMLP_mse = val_loss_traj[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "explicitTSF_mse = val_loss_traj[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_mse = [implicit_mse, explicitTSF_mse, explicitMLP_mse]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    \"explicit-transformer\": \"1ejrnua7\",\n",
    "    \"explicit-mlp\": \"hb9li9ry\",\n",
    "    \"explicit-aux-transformer\": \"hzr77fqz\",\n",
    "    \"implicit\": \"huqr2bcp\",\n",
    "}\n",
    "val_idx = {'iid': 0, 'far': 1, 'wide': 2}\n",
    "\n",
    "\n",
    "def val_intervention_acc(val_style, exp):\n",
    "\n",
    "    api = wandb.Api()\n",
    "    run = api.run(f'leogagnon/Explicit-Implicit/runs/{experiments[exp]}')\n",
    "    artifact = api.artifact(f'leogagnon/Explicit-Implicit/model-{experiments[exp]}:latest')\n",
    "    path = artifact.download()\n",
    "\n",
    "    pl_module = RegressionICL.load_from_checkpoint(\n",
    "        checkpoint_path=os.path.join(path,'model.ckpt'),\n",
    "        strict=False,\n",
    "        model=hydra.utils.instantiate(run.config['model_config']),\n",
    "    ).to('cuda')\n",
    "\n",
    "    class MyConfig(PretrainedConfig):\n",
    "        model_type = 'mymodel'\n",
    "        def __init__(self, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "\n",
    "    class MyModel(PreTrainedModel):\n",
    "        config_class = MyConfig\n",
    "        def __init__(self, config):\n",
    "            super().__init__(config)\n",
    "            self.config = config\n",
    "            self.model = pl_module.model\n",
    "        def forward(self, x_c, y_c, x_q):\n",
    "            return self.model(x_c, y_c, x_q) \n",
    "\n",
    "    hf_model = MyModel(MyConfig())\n",
    "    if exp == \"implicit\":\n",
    "        pv_config = pv.IntervenableConfig(\n",
    "            representations=[\n",
    "                pv.RepresentationConfig(\n",
    "                    component=f\"model.encoder.layers[{i}].output\",\n",
    "                    intervention=pv.LowRankRotatedSpaceIntervention(\n",
    "                        embed_dim=256, low_rank_dimension=10\n",
    "                    )\n",
    "                )\n",
    "                for i in [3,5]\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        pv_config = pv.IntervenableConfig(\n",
    "            representations=pv.RepresentationConfig(\n",
    "                component=\"model.context_model.output\",\n",
    "                intervention=pv.LowRankRotatedSpaceIntervention(\n",
    "                    embed_dim=256, low_rank_dimension=10\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "    pv_model = pv.IntervenableModel(config=pv_config, model=hf_model)\n",
    "    pv_model.set_device(\"cuda\")\n",
    "\n",
    "    datamodule = hydra.utils.instantiate(run.config['experiment_config']['experiment']['data'])\n",
    "\n",
    "    opt = torch.optim.Adam(pv_model.get_trainable_parameters())\n",
    "    pv_model.model.eval()\n",
    "\n",
    "    train_loss_traj = []\n",
    "    val_loss_traj = []\n",
    "    for epoch in range(10):\n",
    "        train_loss = []\n",
    "        for batch in datamodule.train_dataloader():\n",
    "            base = {\n",
    "                \"x_c\": batch[0][0].cuda(),\n",
    "                \"y_c\": batch[0][1].cuda(),\n",
    "                \"x_q\": batch[1][0].cuda(),\n",
    "            }\n",
    "            c_len = batch[0][0].shape[1]\n",
    "\n",
    "            # Different context, different queries, different latent\n",
    "            x_c_source, x_q_source = datamodule.train_data.sample_x(c_len)\n",
    "            w_source = datamodule.train_data.sample_function_params()\n",
    "            source = {\n",
    "                \"x_c\": x_c_source.cuda(),\n",
    "                \"y_c\": datamodule.train_data.function(x_c_source, w_source).cuda(),\n",
    "                \"x_q\": x_q_source.cuda(),\n",
    "            }\n",
    "            unit_locations = (\n",
    "                {\"sources->base\": c_len - 1}\n",
    "                if exp == \"implicit\"\n",
    "                else None\n",
    "            )\n",
    "            y_q_intervened = pv_model(base, source, unit_locations=unit_locations)[1][0]\n",
    "            y_q_counterfactual = datamodule.train_data.function(\n",
    "                batch[1][0], w_source\n",
    "            ).cuda()\n",
    "\n",
    "            loss = torch.nn.functional.mse_loss(y_q_intervened, y_q_counterfactual)\n",
    "\n",
    "            loss.backward()\n",
    "            train_loss += [loss.detach().cpu().item()]\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        train_loss_traj += [sum(train_loss) / len(train_loss)]\n",
    "        print(\"Train loss :\", train_loss_traj[-1])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in datamodule.val_dataloader()[val_idx[val_style]]:\n",
    "                gc.collect()\n",
    "                base = {\n",
    "                    \"x_c\": batch[0][0].cuda(),\n",
    "                    \"y_c\": batch[0][1].cuda(),\n",
    "                    \"x_q\": batch[1][0].cuda(),\n",
    "                }\n",
    "                c_len = batch[0][0].shape[1]\n",
    "                bs = batch[0][0].shape[0]\n",
    "\n",
    "                # Different context, different queries, different latent\n",
    "                x_c_source, x_q_source = datamodule.val_data[val_style].sample_x(\n",
    "                    batch[0][0].shape[1]\n",
    "                )\n",
    "                w_source = datamodule.val_data[val_style].sample_function_params()\n",
    "                source = {\n",
    "                    \"x_c\": x_c_source.cuda(),\n",
    "                    \"y_c\": datamodule.val_data[val_style].function(x_c_source, w_source).cuda(),\n",
    "                    \"x_q\": x_q_source.cuda(),\n",
    "                }\n",
    "\n",
    "                unit_locations = (\n",
    "                    {\"sources->base\": c_len - 1}\n",
    "                    if exp == \"implicit\"\n",
    "                    else None\n",
    "                )\n",
    "                y_q_intervened = pv_model(base, source, unit_locations=unit_locations)[1][0]\n",
    "                y_q_counterfactual = (\n",
    "                    datamodule.val_data[val_style].function(batch[1][0], w_source).cuda()\n",
    "                )\n",
    "\n",
    "                loss = torch.nn.functional.mse_loss(y_q_intervened, y_q_counterfactual)\n",
    "                val_loss_traj += [loss.cpu().item()]\n",
    "                print(\"Val loss :\", loss)\n",
    "    return val_loss_traj[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = torch.zeros(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 4.024337598255703\n",
      "Val loss : tensor(4.0520, device='cuda:0')\n",
      "Train loss : 4.033818449292864\n",
      "Val loss : tensor(3.7802, device='cuda:0')\n",
      "Train loss : 3.94673684665135\n",
      "Val loss : tensor(3.9649, device='cuda:0')\n",
      "Train loss : 3.9697680473327637\n",
      "Val loss : tensor(3.9604, device='cuda:0')\n",
      "Train loss : 3.4926356928689137\n",
      "Val loss : tensor(3.8379, device='cuda:0')\n",
      "Train loss : 3.6506108897072926\n",
      "Val loss : tensor(3.9779, device='cuda:0')\n",
      "Train loss : 3.437436206000192\n",
      "Val loss : tensor(3.8513, device='cuda:0')\n",
      "Train loss : 3.727624007633754\n",
      "Val loss : tensor(3.6758, device='cuda:0')\n",
      "Train loss : 3.6364054339272633\n",
      "Val loss : tensor(3.8207, device='cuda:0')\n",
      "Train loss : 3.5938139983585904\n",
      "Val loss : tensor(3.9750, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "/home/mila/l/leo.gagnon/explicit_implicit_icl/venv/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:177: Found keys that are not in the model state dict but in the checkpoint: ['w_predictor.weight', 'w_predictor.bias']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 3.446636234010969\n",
      "Val loss : tensor(2.4140, device='cuda:0')\n",
      "Train loss : 1.9004792826516288\n",
      "Val loss : tensor(1.1627, device='cuda:0')\n",
      "Train loss : 0.7949495698724475\n",
      "Val loss : tensor(0.4690, device='cuda:0')\n",
      "Train loss : 0.3604810833930969\n",
      "Val loss : tensor(0.2756, device='cuda:0')\n",
      "Train loss : 0.23568803071975708\n",
      "Val loss : tensor(0.1647, device='cuda:0')\n",
      "Train loss : 0.16690210040126527\n",
      "Val loss : tensor(0.1092, device='cuda:0')\n",
      "Train loss : 0.10355858717645917\n",
      "Val loss : tensor(0.0776, device='cuda:0')\n",
      "Train loss : 0.07508943070258413\n",
      "Val loss : tensor(0.0529, device='cuda:0')\n",
      "Train loss : 0.05271272201623235\n",
      "Val loss : tensor(0.0363, device='cuda:0')\n",
      "Train loss : 0.03226178086229733\n",
      "Val loss : tensor(0.0285, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 3.290755646569388\n",
      "Val loss : tensor(2.2651, device='cuda:0')\n",
      "Train loss : 1.4154254964419775\n",
      "Val loss : tensor(0.6661, device='cuda:0')\n",
      "Train loss : 0.3825739004782268\n",
      "Val loss : tensor(0.1407, device='cuda:0')\n",
      "Train loss : 0.09883243324501174\n",
      "Val loss : tensor(0.0549, device='cuda:0')\n",
      "Train loss : 0.0493414332824094\n",
      "Val loss : tensor(0.0295, device='cuda:0')\n",
      "Train loss : 0.034365223720669746\n",
      "Val loss : tensor(0.0330, device='cuda:0')\n",
      "Train loss : 0.02900675604385989\n",
      "Val loss : tensor(0.0232, device='cuda:0')\n",
      "Train loss : 0.023743413920913423\n",
      "Val loss : tensor(0.0214, device='cuda:0')\n",
      "Train loss : 0.02177684647696359\n",
      "Val loss : tensor(0.0225, device='cuda:0')\n",
      "Train loss : 0.020623056750212396\n",
      "Val loss : tensor(0.0229, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 4.11581335748945\n",
      "Val loss : tensor(17.9490, device='cuda:0')\n",
      "Train loss : 3.9308266980307445\n",
      "Val loss : tensor(19.3688, device='cuda:0')\n",
      "Train loss : 3.823661736079625\n",
      "Val loss : tensor(18.1217, device='cuda:0')\n",
      "Train loss : 3.6966682161603654\n",
      "Val loss : tensor(16.9154, device='cuda:0')\n",
      "Train loss : 3.8508084501538957\n",
      "Val loss : tensor(19.1892, device='cuda:0')\n",
      "Train loss : 3.969435146876744\n",
      "Val loss : tensor(19.1610, device='cuda:0')\n",
      "Train loss : 3.8310398374285017\n",
      "Val loss : tensor(18.3594, device='cuda:0')\n",
      "Train loss : 3.937988451548985\n",
      "Val loss : tensor(17.5495, device='cuda:0')\n",
      "Train loss : 3.768394572394235\n",
      "Val loss : tensor(17.9958, device='cuda:0')\n",
      "Train loss : 3.5705741133008684\n",
      "Val loss : tensor(18.6635, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 3.33322879246303\n",
      "Val loss : tensor(14.2756, device='cuda:0')\n",
      "Train loss : 2.0482957533427646\n",
      "Val loss : tensor(7.9235, device='cuda:0')\n",
      "Train loss : 0.7177146417754037\n",
      "Val loss : tensor(3.1705, device='cuda:0')\n",
      "Train loss : 0.3052448460033962\n",
      "Val loss : tensor(2.0574, device='cuda:0')\n",
      "Train loss : 0.21961437804358347\n",
      "Val loss : tensor(1.4731, device='cuda:0')\n",
      "Train loss : 0.14852994041783468\n",
      "Val loss : tensor(1.1051, device='cuda:0')\n",
      "Train loss : 0.13018440987382615\n",
      "Val loss : tensor(1.0032, device='cuda:0')\n",
      "Train loss : 0.08671165257692337\n",
      "Val loss : tensor(0.5897, device='cuda:0')\n",
      "Train loss : 0.04791956075600216\n",
      "Val loss : tensor(0.5229, device='cuda:0')\n",
      "Train loss : 0.04362349824181625\n",
      "Val loss : tensor(0.5376, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 3.0130525657108853\n",
      "Val loss : tensor(9.8643, device='cuda:0')\n",
      "Train loss : 1.2083297201565333\n",
      "Val loss : tensor(2.7634, device='cuda:0')\n",
      "Train loss : 0.28862021224839346\n",
      "Val loss : tensor(1.0503, device='cuda:0')\n",
      "Train loss : 0.0788776885185923\n",
      "Val loss : tensor(0.6031, device='cuda:0')\n",
      "Train loss : 0.04510364548436233\n",
      "Val loss : tensor(0.4247, device='cuda:0')\n",
      "Train loss : 0.029282756948045323\n",
      "Val loss : tensor(0.4210, device='cuda:0')\n",
      "Train loss : 0.025934356397816112\n",
      "Val loss : tensor(0.3175, device='cuda:0')\n",
      "Train loss : 0.02336400587643896\n",
      "Val loss : tensor(0.3673, device='cuda:0')\n",
      "Train loss : 0.02277025327618633\n",
      "Val loss : tensor(0.3855, device='cuda:0')\n",
      "Train loss : 0.018095331000430242\n",
      "Val loss : tensor(0.3093, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i, v in enumerate([\"iid\", \"wide\"]):\n",
    "    for j, e in enumerate([\"implicit\", \"explicit-transformer\", \"explicit-mlp\"]):\n",
    "        accs[i, j] = val_intervention_acc(v, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.melt(\n",
    "    pd.DataFrame(accs).reset_index(),\n",
    "    id_vars=\"index\",\n",
    "    var_name=\"Model\",\n",
    "    value_name=\"value\",\n",
    ")\n",
    "data.rename(columns={\"index\": \"OOD style\"}, inplace=True)\n",
    "data.rename(columns={\"value\": \"Counterfactual MSE\"}, inplace=True)\n",
    "\n",
    "data['Model'] = data['Model'].map({0: 'Implicit', 1: 'Explicit Transformer', 2: 'Explicit MLP'})\n",
    "data['OOD style'] = data['OOD style'].map({0: 'IID', 1: 'OOD',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style for making nice-looking paper plots with page-scale figure size units\n",
    "sns.set_theme(\n",
    "    style=\"ticks\",\n",
    "    context=\"paper\",\n",
    "    rc={\n",
    "        \"font.size\": 5,\n",
    "        \"axes.titlesize\": 6,\n",
    "        \"axes.labelsize\": 6,\n",
    "        \"axes.labelpad\": 2,\n",
    "        \"xtick.labelsize\": 4.5,\n",
    "        \"ytick.labelsize\": 4.5,\n",
    "        \"legend.title_fontsize\": 4.5,\n",
    "        \"legend.fontsize\": 4.5,\n",
    "        \"legend.markerscale\": 0.5,\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "        \"axes.linewidth\": 0.4,\n",
    "        \"xtick.major.width\": 0.4,\n",
    "        \"ytick.major.width\": 0.4,\n",
    "        \"xtick.major.size\": 2.5,\n",
    "        \"ytick.major.size\": 2.5,\n",
    "        \"xtick.minor.size\": 1.5,\n",
    "        \"ytick.minor.size\": 1.5,\n",
    "        \"xtick.minor.width\": 0.2,\n",
    "        \"ytick.minor.width\": 0.2,\n",
    "        \"figure.constrained_layout.use\": True,\n",
    "        \"figure.dpi\": 200,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/l/leo.gagnon/explicit_implicit_icl/venv/lib/python3.10/site-packages/seaborn/_base.py:949: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/home/mila/l/leo.gagnon/explicit_implicit_icl/venv/lib/python3.10/site-packages/seaborn/_base.py:949: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/home/mila/l/leo.gagnon/explicit_implicit_icl/venv/lib/python3.10/site-packages/seaborn/_base.py:949: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 10.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x220 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "default_model_colours = {\n",
    "    \"implicit\": sns.color_palette()[7],\n",
    "    \"explicit-transformer\": sns.color_palette()[0],\n",
    "    \"explicit-mlp\": sns.color_palette()[1],\n",
    "    \"explicit-aux-transformer\": sns.color_palette()[4],\n",
    "    \"explicit-known\": sns.color_palette()[2],\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2, 1.1))\n",
    "\n",
    "sns.barplot(\n",
    "    data=data,\n",
    "    ax=ax,\n",
    "    x=\"OOD style\",\n",
    "    y=\"Counterfactual MSE\",\n",
    "    hue=\"Model\",\n",
    "    hue_order=[\"Implicit\", \"Explicit Transformer\", \"Explicit MLP\"],\n",
    "    palette=[\n",
    "        default_model_colours[m]\n",
    "        for m in [\"implicit\", \"explicit-transformer\", \"explicit-mlp\"]\n",
    "    ],\n",
    "    err_kws={\"linewidth\": 1.25},\n",
    ")\n",
    "ax.legend().remove()\n",
    "ax.set(\n",
    "    title=\"Linear regression interventions\",\n",
    "    xlabel=\"Validation data\",\n",
    "    ylabel=r\"Counterfactual MSE ($\\downarrow$)\",\n",
    ")\n",
    "ax.set_ylim([0,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
