{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "from einops import repeat\n",
    "import pyvene as pv\n",
    "import torch\n",
    "import wandb\n",
    "from tasks.regression import *\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    \"explicit-transformer\": \"1ejrnua7\",\n",
    "    \"explicit-mlp\": \"hb9li9ry\",\n",
    "    \"explicit-aux-transformer\": \"hzr77fqz\",\n",
    "    \"implicit\": \"huqr2bcp\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP = 'explicit-transformer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "run = api.run(f'leogagnon/Explicit-Implicit/runs/{experiments[EXP]}')\n",
    "artifact = api.artifact(f'leogagnon/Explicit-Implicit/model-{experiments[EXP]}:latest')\n",
    "path = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/l/leo.gagnon/explicit_implicit_icl/venv/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:177: Found keys that are not in the model state dict but in the checkpoint: ['w_predictor.weight', 'w_predictor.bias']\n"
     ]
    }
   ],
   "source": [
    "pl_module = RegressionICL.load_from_checkpoint(\n",
    "    checkpoint_path=os.path.join(path,'model.ckpt'),\n",
    "    strict=False,\n",
    "    model=hydra.utils.instantiate(run.config['model_config']),\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConfig(PretrainedConfig):\n",
    "    model_type = 'mymodel'\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "class MyModel(PreTrainedModel):\n",
    "    config_class = MyConfig\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        self.model = pl_module.model\n",
    "    def forward(self, x_c, y_c, x_q):\n",
    "        return self.model(x_c, y_c, x_q) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model = MyModel(MyConfig())\n",
    "if EXP == \"implicit\":\n",
    "    pv_config = pv.IntervenableConfig(\n",
    "        representations=[\n",
    "            pv.RepresentationConfig(\n",
    "                component=f\"model.encoder.layers[{i}].output\",\n",
    "                intervention=pv.LowRankRotatedSpaceIntervention(\n",
    "                    embed_dim=256, low_rank_dimension=10\n",
    "                )\n",
    "            )\n",
    "            for i in [3,5]\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    pv_config = pv.IntervenableConfig(\n",
    "        representations=pv.RepresentationConfig(\n",
    "            component=\"model.context_model.output\",\n",
    "            intervention=pv.LowRankRotatedSpaceIntervention(\n",
    "                embed_dim=256, low_rank_dimension=10\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "pv_model = pv.IntervenableModel(config=pv_config, model=hf_model)\n",
    "pv_model.set_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = hydra.utils.instantiate(run.config['experiment_config']['experiment']['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = {'iid': 0, 'far': 1, 'wide': 2}\n",
    "VAL_STYLE = 'wide'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 3.198320116315569\n",
      "Val loss : tensor(13.1080, device='cuda:0')\n",
      "Train loss : 1.874198590006147\n",
      "Val loss : tensor(6.2786, device='cuda:0')\n",
      "Train loss : 0.5793971355472293\n",
      "Val loss : tensor(2.3316, device='cuda:0')\n",
      "Train loss : 0.22932793625763484\n",
      "Val loss : tensor(1.2753, device='cuda:0')\n",
      "Train loss : 0.15301584558827536\n",
      "Val loss : tensor(0.9138, device='cuda:0')\n",
      "Train loss : 0.10284969849245888\n",
      "Val loss : tensor(0.7651, device='cuda:0')\n",
      "Train loss : 0.05476683271782739\n",
      "Val loss : tensor(0.5624, device='cuda:0')\n",
      "Train loss : 0.03585385424750192\n",
      "Val loss : tensor(0.5677, device='cuda:0')\n",
      "Train loss : 0.03415108525327274\n",
      "Val loss : tensor(0.5631, device='cuda:0')\n",
      "Train loss : 0.02626355178654194\n",
      "Val loss : tensor(0.5083, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(pv_model.get_trainable_parameters())\n",
    "pv_model.model.eval()\n",
    "\n",
    "train_loss_traj = []\n",
    "val_loss_traj = []\n",
    "for epoch in range(10):\n",
    "    train_loss = []\n",
    "    for batch in datamodule.train_dataloader():\n",
    "        base = {\n",
    "            \"x_c\": batch[0][0].cuda(),\n",
    "            \"y_c\": batch[0][1].cuda(),\n",
    "            \"x_q\": batch[1][0].cuda(),\n",
    "        }\n",
    "        c_len = batch[0][0].shape[1]\n",
    "\n",
    "        # Different context, different queries, different latent\n",
    "        x_c_source, x_q_source = datamodule.train_data.sample_x(c_len)\n",
    "        w_source = datamodule.train_data.sample_function_params()\n",
    "        source = {\n",
    "            \"x_c\": x_c_source.cuda(),\n",
    "            \"y_c\": datamodule.train_data.function(x_c_source, w_source).cuda(),\n",
    "            \"x_q\": x_q_source.cuda(),\n",
    "        }\n",
    "        unit_locations = (\n",
    "            {\"sources->base\": c_len - 1}\n",
    "            if EXP == \"implicit\"\n",
    "            else None\n",
    "        )\n",
    "        y_q_intervened = pv_model(base, source, unit_locations=unit_locations)[1][0]\n",
    "        y_q_counterfactual = datamodule.train_data.function(\n",
    "            batch[1][0], w_source\n",
    "        ).cuda()\n",
    "\n",
    "        loss = torch.nn.functional.mse_loss(y_q_intervened, y_q_counterfactual)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += [loss.detach().cpu().item()]\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    train_loss_traj += [sum(train_loss) / len(train_loss)]\n",
    "    print(\"Train loss :\", train_loss_traj[-1])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in datamodule.val_dataloader()[val_idx[VAL_STYLE]]:\n",
    "            gc.collect()\n",
    "            base = {\n",
    "                \"x_c\": batch[0][0].cuda(),\n",
    "                \"y_c\": batch[0][1].cuda(),\n",
    "                \"x_q\": batch[1][0].cuda(),\n",
    "            }\n",
    "            c_len = batch[0][0].shape[1]\n",
    "            bs = batch[0][0].shape[0]\n",
    "\n",
    "            # Different context, different queries, different latent\n",
    "            x_c_source, x_q_source = datamodule.val_data[VAL_STYLE].sample_x(\n",
    "                batch[0][0].shape[1]\n",
    "            )\n",
    "            w_source = datamodule.val_data[VAL_STYLE].sample_function_params()\n",
    "            source = {\n",
    "                \"x_c\": x_c_source.cuda(),\n",
    "                \"y_c\": datamodule.val_data[VAL_STYLE].function(x_c_source, w_source).cuda(),\n",
    "                \"x_q\": x_q_source.cuda(),\n",
    "            }\n",
    "\n",
    "            unit_locations = (\n",
    "                {\"sources->base\": c_len - 1}\n",
    "                if EXP == \"implicit\"\n",
    "                else None\n",
    "            )\n",
    "            y_q_intervened = pv_model(base, source, unit_locations=unit_locations)[1][0]\n",
    "            y_q_counterfactual = (\n",
    "                datamodule.val_data[VAL_STYLE].function(batch[1][0], w_source).cuda()\n",
    "            )\n",
    "\n",
    "            loss = torch.nn.functional.mse_loss(y_q_intervened, y_q_counterfactual)\n",
    "            val_loss_traj += [loss.cpu().item()]\n",
    "            print(\"Val loss :\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit_mse = val_loss_traj[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "explicitMLP_mse = val_loss_traj[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "explicitTSF_mse = val_loss_traj[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_mse = [implicit_mse, explicitTSF_mse, explicitMLP_mse]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    \"explicit-transformer\": \"1ejrnua7\",\n",
    "    \"explicit-mlp\": \"hb9li9ry\",\n",
    "    \"explicit-aux-transformer\": \"hzr77fqz\",\n",
    "    \"implicit\": \"huqr2bcp\",\n",
    "}\n",
    "val_idx = {'iid': 0, 'far': 1, 'wide': 2}\n",
    "\n",
    "\n",
    "def val_intervention_acc(val_style, exp):\n",
    "\n",
    "    api = wandb.Api()\n",
    "    run = api.run(f'leogagnon/Explicit-Implicit/runs/{experiments[exp]}')\n",
    "    artifact = api.artifact(f'leogagnon/Explicit-Implicit/model-{experiments[exp]}:latest')\n",
    "    path = artifact.download()\n",
    "\n",
    "    pl_module = RegressionICL.load_from_checkpoint(\n",
    "        checkpoint_path=os.path.join(path,'model.ckpt'),\n",
    "        strict=False,\n",
    "        model=hydra.utils.instantiate(run.config['model_config']),\n",
    "    ).to('cuda')\n",
    "\n",
    "    class MyConfig(PretrainedConfig):\n",
    "        model_type = 'mymodel'\n",
    "        def __init__(self, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "\n",
    "    class MyModel(PreTrainedModel):\n",
    "        config_class = MyConfig\n",
    "        def __init__(self, config):\n",
    "            super().__init__(config)\n",
    "            self.config = config\n",
    "            self.model = pl_module.model\n",
    "        def forward(self, x_c, y_c, x_q):\n",
    "            return self.model(x_c, y_c, x_q) \n",
    "\n",
    "    hf_model = MyModel(MyConfig())\n",
    "    if exp == \"implicit\":\n",
    "        pv_config = pv.IntervenableConfig(\n",
    "            representations=[\n",
    "                pv.RepresentationConfig(\n",
    "                    component=f\"model.encoder.layers[{i}].output\",\n",
    "                    intervention=pv.LowRankRotatedSpaceIntervention(\n",
    "                        embed_dim=256, low_rank_dimension=10\n",
    "                    )\n",
    "                )\n",
    "                for i in [3,5]\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        pv_config = pv.IntervenableConfig(\n",
    "            representations=pv.RepresentationConfig(\n",
    "                component=\"model.context_model.output\",\n",
    "                intervention=pv.LowRankRotatedSpaceIntervention(\n",
    "                    embed_dim=256, low_rank_dimension=10\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "    pv_model = pv.IntervenableModel(config=pv_config, model=hf_model)\n",
    "    pv_model.set_device(\"cuda\")\n",
    "\n",
    "    datamodule = hydra.utils.instantiate(run.config['experiment_config']['experiment']['data'])\n",
    "\n",
    "    opt = torch.optim.Adam(pv_model.get_trainable_parameters())\n",
    "    pv_model.model.eval()\n",
    "\n",
    "    train_loss_traj = []\n",
    "    val_loss_traj = []\n",
    "    for epoch in range(10):\n",
    "        train_loss = []\n",
    "        for batch in datamodule.train_dataloader():\n",
    "            base = {\n",
    "                \"x_c\": batch[0][0].cuda(),\n",
    "                \"y_c\": batch[0][1].cuda(),\n",
    "                \"x_q\": batch[1][0].cuda(),\n",
    "            }\n",
    "            c_len = batch[0][0].shape[1]\n",
    "\n",
    "            # Different context, different queries, different latent\n",
    "            x_c_source, x_q_source = datamodule.train_data.sample_x(c_len)\n",
    "            w_source = datamodule.train_data.sample_function_params()\n",
    "            source = {\n",
    "                \"x_c\": x_c_source.cuda(),\n",
    "                \"y_c\": datamodule.train_data.function(x_c_source, w_source).cuda(),\n",
    "                \"x_q\": x_q_source.cuda(),\n",
    "            }\n",
    "            unit_locations = (\n",
    "                {\"sources->base\": c_len - 1}\n",
    "                if exp == \"implicit\"\n",
    "                else None\n",
    "            )\n",
    "            y_q_intervened = pv_model(base, source, unit_locations=unit_locations)[1][0]\n",
    "            y_q_counterfactual = datamodule.train_data.function(\n",
    "                batch[1][0], w_source\n",
    "            ).cuda()\n",
    "\n",
    "            loss = torch.nn.functional.mse_loss(y_q_intervened, y_q_counterfactual)\n",
    "\n",
    "            loss.backward()\n",
    "            train_loss += [loss.detach().cpu().item()]\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        train_loss_traj += [sum(train_loss) / len(train_loss)]\n",
    "        print(\"Train loss :\", train_loss_traj[-1])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in datamodule.val_dataloader()[val_idx[val_style]]:\n",
    "                gc.collect()\n",
    "                base = {\n",
    "                    \"x_c\": batch[0][0].cuda(),\n",
    "                    \"y_c\": batch[0][1].cuda(),\n",
    "                    \"x_q\": batch[1][0].cuda(),\n",
    "                }\n",
    "                c_len = batch[0][0].shape[1]\n",
    "                bs = batch[0][0].shape[0]\n",
    "\n",
    "                # Different context, different queries, different latent\n",
    "                x_c_source, x_q_source = datamodule.val_data[val_style].sample_x(\n",
    "                    batch[0][0].shape[1]\n",
    "                )\n",
    "                w_source = datamodule.val_data[val_style].sample_function_params()\n",
    "                source = {\n",
    "                    \"x_c\": x_c_source.cuda(),\n",
    "                    \"y_c\": datamodule.val_data[val_style].function(x_c_source, w_source).cuda(),\n",
    "                    \"x_q\": x_q_source.cuda(),\n",
    "                }\n",
    "\n",
    "                unit_locations = (\n",
    "                    {\"sources->base\": c_len - 1}\n",
    "                    if exp == \"implicit\"\n",
    "                    else None\n",
    "                )\n",
    "                y_q_intervened = pv_model(base, source, unit_locations=unit_locations)[1][0]\n",
    "                y_q_counterfactual = (\n",
    "                    datamodule.val_data[val_style].function(batch[1][0], w_source).cuda()\n",
    "                )\n",
    "\n",
    "                loss = torch.nn.functional.mse_loss(y_q_intervened, y_q_counterfactual)\n",
    "                val_loss_traj += [loss.cpu().item()]\n",
    "                print(\"Val loss :\", loss)\n",
    "    return val_loss_traj[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = torch.zeros(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in enumerate([\"iid\", \"far\", \"wide\"]):\n",
    "    for j, e in enumerate([\"implicit\", \"explicit-transformer\", \"explicit-mlp\"]):\n",
    "        accs[i, j] = val_intervention_acc(v, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.melt(\n",
    "    pd.DataFrame(accs).reset_index(),\n",
    "    id_vars=\"index\",\n",
    "    var_name=\"Model\",\n",
    "    value_name=\"value\",\n",
    ")\n",
    "data.rename(columns={\"index\": \"OOD style\"}, inplace=True)\n",
    "data.rename(columns={\"value\": \"Counterfactual MSE\"}, inplace=True)\n",
    "\n",
    "data['Model'] = data['Model'].map({0: 'Implicit', 1: 'Explicit Transformer', 2: 'Explicit MLP'})\n",
    "data['OOD style'] = data['OOD style'].map({0: 'IID', 1: 'Far', 2: 'Wide'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style for making nice-looking paper plots with page-scale figure size units\n",
    "sns.set_theme(\n",
    "    style=\"ticks\",\n",
    "    context=\"paper\",\n",
    "    rc={\n",
    "        \"font.size\": 5,\n",
    "        \"axes.titlesize\": 6,\n",
    "        \"axes.labelsize\": 6,\n",
    "        \"axes.labelpad\": 2,\n",
    "        \"xtick.labelsize\": 4.5,\n",
    "        \"ytick.labelsize\": 4.5,\n",
    "        \"legend.title_fontsize\": 4.5,\n",
    "        \"legend.fontsize\": 4.5,\n",
    "        \"legend.markerscale\": 0.5,\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "        \"axes.linewidth\": 0.4,\n",
    "        \"xtick.major.width\": 0.4,\n",
    "        \"ytick.major.width\": 0.4,\n",
    "        \"xtick.major.size\": 2.5,\n",
    "        \"ytick.major.size\": 2.5,\n",
    "        \"xtick.minor.size\": 1.5,\n",
    "        \"ytick.minor.size\": 1.5,\n",
    "        \"xtick.minor.width\": 0.2,\n",
    "        \"ytick.minor.width\": 0.2,\n",
    "        \"figure.constrained_layout.use\": True,\n",
    "        \"figure.dpi\": 200,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/l/leo.gagnon/explicit_implicit_icl/venv/lib/python3.10/site-packages/seaborn/_base.py:949: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/home/mila/l/leo.gagnon/explicit_implicit_icl/venv/lib/python3.10/site-packages/seaborn/_base.py:949: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/home/mila/l/leo.gagnon/explicit_implicit_icl/venv/lib/python3.10/site-packages/seaborn/_base.py:949: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 2.0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x110 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "default_model_colours = {\n",
    "    \"implicit\": sns.color_palette()[7],\n",
    "    \"explicit-transformer\": sns.color_palette()[0],\n",
    "    \"explicit-mlp\": sns.color_palette()[1],\n",
    "    \"explicit-aux-transformer\": sns.color_palette()[4],\n",
    "    \"explicit-known\": sns.color_palette()[2],\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2, 1.1))\n",
    "\n",
    "sns.barplot(\n",
    "    data=data,\n",
    "    ax=ax,\n",
    "    x=\"OOD style\",\n",
    "    y=\"Counterfactual MSE\",\n",
    "    hue=\"Model\",\n",
    "    hue_order=[\"Implicit\", \"Explicit Transformer\", \"Explicit MLP\"],\n",
    "    palette=[\n",
    "        default_model_colours[m]\n",
    "        for m in [\"implicit\", \"explicit-transformer\", \"explicit-mlp\"]\n",
    "    ],\n",
    "    err_kws={\"linewidth\": 1.25},\n",
    ")\n",
    "ax.legend().remove()\n",
    "ax.set(\n",
    "    title=\"Alchemy\",\n",
    "    xlabel=\"Latent component\",\n",
    "    ylabel=r\"Counterfactual MSE ($\\uparrow$)\",\n",
    ")\n",
    "ax.set_ylim([0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
