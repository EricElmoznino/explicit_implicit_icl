{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "from einops import repeat\n",
    "import pyvene as pv\n",
    "import torch\n",
    "import wandb\n",
    "from tasks.regression import *\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "Doesn't include Alchemy interpretability experiments, which unfortunately didn't get integrated into this repo yet (they were done in an other one). However they should be very easy to do by extending the code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    \"explicit-transformer\": \"1ejrnua7\",\n",
    "    \"explicit-mlp\": \"hb9li9ry\",\n",
    "    \"explicit-aux-transformer\": \"hzr77fqz\",\n",
    "    \"implicit\": \"huqr2bcp\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP = 'implicit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "run = api.run(f'leogagnon/Explicit-Implicit/runs/{experiments[EXP]}')\n",
    "artifact = api.artifact(f'leogagnon/Explicit-Implicit/model-{experiments[EXP]}:latest')\n",
    "path = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_module = RegressionICL.load_from_checkpoint(\n",
    "    checkpoint_path=os.path.join(path,'model.ckpt'),\n",
    "    strict=False,\n",
    "    model=hydra.utils.instantiate(run.config['model_config']),\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConfig(PretrainedConfig):\n",
    "    model_type = 'mymodel'\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "class MyModel(PreTrainedModel):\n",
    "    config_class = MyConfig\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        self.model = pl_module.model\n",
    "    def forward(self, x_c, y_c, x_q):\n",
    "        return self.model(x_c, y_c, x_q) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(2) for j in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model = MyModel(MyConfig())\n",
    "if EXP == \"implicit\":\n",
    "    pv_config = pv.IntervenableConfig(\n",
    "        representations=[\n",
    "            pv.RepresentationConfig(\n",
    "                component=f\"model.encoder.layers[{l}].output\",\n",
    "                intervention=pv.LowRankRotatedSpaceIntervention(\n",
    "                    embed_dim=256, low_rank_dimension=10, keep_last_dim=True\n",
    "                ),\n",
    "            )\n",
    "            for l in [2,3,5]\n",
    "        ]\n",
    "    )\n",
    "else:\n",
    "    pv_config = pv.IntervenableConfig(\n",
    "        representations=pv.RepresentationConfig(\n",
    "            component=\"model.context_model.output\",\n",
    "            intervention=pv.LowRankRotatedSpaceIntervention(\n",
    "                embed_dim=256, low_rank_dimension=10\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "pv_model = pv.IntervenableModel(config=pv_config, model=hf_model)\n",
    "pv_model.set_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = hydra.utils.instantiate(run.config['experiment_config']['experiment']['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = {'iid': 0, 'far': 1, 'wide': 2}\n",
    "VAL_STYLE = 'wide'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 2.360770344734192\n",
      "Val loss : tensor(4.6505, device='cuda:0')\n",
      "Train loss : 0.5791825907570975\n",
      "Val loss : tensor(2.1302, device='cuda:0')\n",
      "Train loss : 0.2606759603534426\n",
      "Val loss : tensor(1.7268, device='cuda:0')\n",
      "Train loss : 0.14732533480439866\n",
      "Val loss : tensor(1.5393, device='cuda:0')\n",
      "Train loss : 0.10062737337180547\n",
      "Val loss : tensor(1.3253, device='cuda:0')\n",
      "Train loss : 0.07483400404453278\n",
      "Val loss : tensor(1.3590, device='cuda:0')\n",
      "Train loss : 0.06655098018901688\n",
      "Val loss : tensor(1.0370, device='cuda:0')\n",
      "Train loss : 0.04967491488371577\n",
      "Val loss : tensor(1.0519, device='cuda:0')\n",
      "Train loss : 0.051599811762571335\n",
      "Val loss : tensor(1.0727, device='cuda:0')\n",
      "Train loss : 0.03970677964389324\n",
      "Val loss : tensor(0.9081, device='cuda:0')\n",
      "Train loss : 0.03521640492337091\n",
      "Val loss : tensor(0.7734, device='cuda:0')\n",
      "Train loss : 0.026427481855664934\n",
      "Val loss : tensor(0.7373, device='cuda:0')\n",
      "Train loss : 0.027114037158233777\n",
      "Val loss : tensor(0.7432, device='cuda:0')\n",
      "Train loss : 0.026184880839926854\n",
      "Val loss : tensor(0.6253, device='cuda:0')\n",
      "Train loss : 0.02227629455072539\n",
      "Val loss : tensor(0.6676, device='cuda:0')\n",
      "Train loss : 0.019681723655334542\n",
      "Val loss : tensor(0.6734, device='cuda:0')\n",
      "Train loss : 0.0179298214082207\n",
      "Val loss : tensor(0.8093, device='cuda:0')\n",
      "Train loss : 0.01598755975386926\n",
      "Val loss : tensor(0.7265, device='cuda:0')\n",
      "Train loss : 0.01569007390311786\n",
      "Val loss : tensor(0.6715, device='cuda:0')\n",
      "Train loss : 0.015050479477005345\n",
      "Val loss : tensor(0.6834, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adam(pv_model.get_trainable_parameters())\n",
    "pv_model.model.eval()\n",
    "\n",
    "train_loss_traj = []\n",
    "val_loss_traj = []\n",
    "for epoch in range(20):\n",
    "    train_loss = []\n",
    "    for batch in datamodule.train_dataloader():\n",
    "        base = {\n",
    "            \"x_c\": batch[0][0].cuda(),\n",
    "            \"y_c\": batch[0][1].cuda(),\n",
    "            \"x_q\": batch[1][0].cuda(),\n",
    "        }\n",
    "        c_len = batch[0][0].shape[1]\n",
    "        bs = batch[0][0].shape[0]\n",
    "\n",
    "        # Different context, different queries, different latent\n",
    "        x_c_source, x_q_source = datamodule.train_data.sample_x(c_len)\n",
    "        w_source = datamodule.train_data.sample_function_params()\n",
    "        source = {\n",
    "            \"x_c\": x_c_source.cuda(),\n",
    "            \"y_c\": datamodule.train_data.function(x_c_source, w_source).cuda(),\n",
    "            \"x_q\": batch[1][0].cuda(),\n",
    "        }\n",
    "        loc = [[[[(c_len + i) for i in range(c_len)]] * bs] * 3] * 2\n",
    "        unit_locations = {\"sources->base\": loc} if EXP == \"implicit\" else None\n",
    "        y_q_intervened = pv_model(base, source, unit_locations=unit_locations)[1][0]\n",
    "        y_q_counterfactual = datamodule.train_data.function(\n",
    "            batch[1][0], w_source\n",
    "        ).cuda()\n",
    "\n",
    "        loss = torch.nn.functional.mse_loss(y_q_intervened, y_q_counterfactual)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += [loss.detach().cpu().item()]\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    train_loss_traj += [sum(train_loss) / len(train_loss)]\n",
    "    print(\"Train loss :\", train_loss_traj[-1])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in datamodule.val_dataloader()[val_idx[VAL_STYLE]]:\n",
    "            gc.collect()\n",
    "            base = {\n",
    "                \"x_c\": batch[0][0].cuda(),\n",
    "                \"y_c\": batch[0][1].cuda(),\n",
    "                \"x_q\": batch[1][0].cuda(),\n",
    "            }\n",
    "            c_len = batch[0][0].shape[1]\n",
    "            bs = batch[0][0].shape[0]\n",
    "\n",
    "            # Different context, different queries, different latent\n",
    "            x_c_source, x_q_source = datamodule.val_data[VAL_STYLE].sample_x(\n",
    "                batch[0][0].shape[1]\n",
    "            )\n",
    "            w_source = datamodule.val_data[VAL_STYLE].sample_function_params()\n",
    "            source = {\n",
    "                \"x_c\": x_c_source.cuda(),\n",
    "                \"y_c\": datamodule.val_data[VAL_STYLE]\n",
    "                .function(x_c_source, w_source)\n",
    "                .cuda(),\n",
    "                \"x_q\": batch[1][0].cuda(),\n",
    "            }\n",
    "\n",
    "            loc = [[[[(c_len + i) for i in range(c_len)]] * bs] * 3] * 2\n",
    "            unit_locations = {\"sources->base\": loc} if EXP == \"implicit\" else None\n",
    "            y_q_intervened = pv_model(base, source, unit_locations=unit_locations)[1][0]\n",
    "            y_q_counterfactual = (\n",
    "                datamodule.val_data[VAL_STYLE].function(batch[1][0], w_source).cuda()\n",
    "            )\n",
    "\n",
    "            loss = torch.nn.functional.mse_loss(y_q_intervened, y_q_counterfactual)\n",
    "            val_loss_traj += [loss.cpu().item()]\n",
    "            print(\"Val loss :\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit_mse = val_loss_traj[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "explicitMLP_mse = val_loss_traj[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "explicitTSF_mse = val_loss_traj[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_mse = [implicit_mse, explicitTSF_mse, explicitMLP_mse]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    \"explicit-transformer\": \"1ejrnua7\",\n",
    "    \"explicit-mlp\": \"hb9li9ry\",\n",
    "    \"explicit-aux-transformer\": \"hzr77fqz\",\n",
    "    \"implicit\": \"huqr2bcp\",\n",
    "}\n",
    "val_idx = {'iid': 0, 'far': 1, 'wide': 2}\n",
    "\n",
    "\n",
    "def val_intervention_acc(val_style, exp):\n",
    "\n",
    "    api = wandb.Api()\n",
    "    run = api.run(f'leogagnon/Explicit-Implicit/runs/{experiments[exp]}')\n",
    "    artifact = api.artifact(f'leogagnon/Explicit-Implicit/model-{experiments[exp]}:latest')\n",
    "    path = artifact.download()\n",
    "\n",
    "    pl_module = RegressionICL.load_from_checkpoint(\n",
    "        checkpoint_path=os.path.join(path,'model.ckpt'),\n",
    "        strict=False,\n",
    "        model=hydra.utils.instantiate(run.config['model_config']),\n",
    "    ).to('cuda')\n",
    "\n",
    "    class MyConfig(PretrainedConfig):\n",
    "        model_type = 'mymodel'\n",
    "        def __init__(self, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "\n",
    "    class MyModel(PreTrainedModel):\n",
    "        config_class = MyConfig\n",
    "        def __init__(self, config):\n",
    "            super().__init__(config)\n",
    "            self.config = config\n",
    "            self.model = pl_module.model\n",
    "        def forward(self, x_c, y_c, x_q):\n",
    "            return self.model(x_c, y_c, x_q) \n",
    "\n",
    "    hf_model = MyModel(MyConfig())\n",
    "    if exp == \"implicit\":\n",
    "        pv_config = pv.IntervenableConfig(\n",
    "            representations=[\n",
    "                pv.RepresentationConfig(\n",
    "                    component=f\"model.encoder.layers[{i}].output\",\n",
    "                    intervention=pv.LowRankRotatedSpaceIntervention(\n",
    "                        embed_dim=256, low_rank_dimension=10\n",
    "                    )\n",
    "                )\n",
    "                for i in [3,5]\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        pv_config = pv.IntervenableConfig(\n",
    "            representations=pv.RepresentationConfig(\n",
    "                component=\"model.context_model.output\",\n",
    "                intervention=pv.LowRankRotatedSpaceIntervention(\n",
    "                    embed_dim=256, low_rank_dimension=10\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "    pv_model = pv.IntervenableModel(config=pv_config, model=hf_model)\n",
    "    pv_model.set_device(\"cuda\")\n",
    "\n",
    "    datamodule = hydra.utils.instantiate(run.config['experiment_config']['experiment']['data'])\n",
    "\n",
    "    opt = torch.optim.Adam(pv_model.get_trainable_parameters())\n",
    "    pv_model.model.eval()\n",
    "\n",
    "    train_loss_traj = []\n",
    "    val_loss_traj = []\n",
    "    for epoch in range(10):\n",
    "        train_loss = []\n",
    "        for batch in datamodule.train_dataloader():\n",
    "            base = {\n",
    "                \"x_c\": batch[0][0].cuda(),\n",
    "                \"y_c\": batch[0][1].cuda(),\n",
    "                \"x_q\": batch[1][0].cuda(),\n",
    "            }\n",
    "            c_len = batch[0][0].shape[1]\n",
    "\n",
    "            # Different context, different queries, different latent\n",
    "            x_c_source, x_q_source = datamodule.train_data.sample_x(c_len)\n",
    "            w_source = datamodule.train_data.sample_function_params()\n",
    "            source = {\n",
    "                \"x_c\": x_c_source.cuda(),\n",
    "                \"y_c\": datamodule.train_data.function(x_c_source, w_source).cuda(),\n",
    "                \"x_q\": x_q_source.cuda(),\n",
    "            }\n",
    "            unit_locations = (\n",
    "                {\"sources->base\": c_len - 1}\n",
    "                if exp == \"implicit\"\n",
    "                else None\n",
    "            )\n",
    "            y_q_intervened = pv_model(base, source, unit_locations=unit_locations)[1][0]\n",
    "            y_q_counterfactual = datamodule.train_data.function(\n",
    "                batch[1][0], w_source\n",
    "            ).cuda()\n",
    "\n",
    "            loss = torch.nn.functional.mse_loss(y_q_intervened, y_q_counterfactual)\n",
    "\n",
    "            loss.backward()\n",
    "            train_loss += [loss.detach().cpu().item()]\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        train_loss_traj += [sum(train_loss) / len(train_loss)]\n",
    "        print(\"Train loss :\", train_loss_traj[-1])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in datamodule.val_dataloader()[val_idx[val_style]]:\n",
    "                gc.collect()\n",
    "                base = {\n",
    "                    \"x_c\": batch[0][0].cuda(),\n",
    "                    \"y_c\": batch[0][1].cuda(),\n",
    "                    \"x_q\": batch[1][0].cuda(),\n",
    "                }\n",
    "                c_len = batch[0][0].shape[1]\n",
    "                bs = batch[0][0].shape[0]\n",
    "\n",
    "                # Different context, different queries, different latent\n",
    "                x_c_source, x_q_source = datamodule.val_data[val_style].sample_x(\n",
    "                    batch[0][0].shape[1]\n",
    "                )\n",
    "                w_source = datamodule.val_data[val_style].sample_function_params()\n",
    "                source = {\n",
    "                    \"x_c\": x_c_source.cuda(),\n",
    "                    \"y_c\": datamodule.val_data[val_style].function(x_c_source, w_source).cuda(),\n",
    "                    \"x_q\": x_q_source.cuda(),\n",
    "                }\n",
    "\n",
    "                unit_locations = (\n",
    "                    {\"sources->base\": c_len - 1}\n",
    "                    if exp == \"implicit\"\n",
    "                    else None\n",
    "                )\n",
    "                y_q_intervened = pv_model(base, source, unit_locations=unit_locations)[1][0]\n",
    "                y_q_counterfactual = (\n",
    "                    datamodule.val_data[val_style].function(batch[1][0], w_source).cuda()\n",
    "                )\n",
    "\n",
    "                loss = torch.nn.functional.mse_loss(y_q_intervened, y_q_counterfactual)\n",
    "                val_loss_traj += [loss.cpu().item()]\n",
    "                print(\"Val loss :\", loss)\n",
    "    return val_loss_traj[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = torch.zeros(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 4.011986323765346\n",
      "Val loss : tensor(4.0815, device='cuda:0')\n",
      "Train loss : 4.0267515523093085\n",
      "Val loss : tensor(3.7923, device='cuda:0')\n",
      "Train loss : 3.7273685250963484\n",
      "Val loss : tensor(3.9347, device='cuda:0')\n",
      "Train loss : 3.764397621154785\n",
      "Val loss : tensor(3.7408, device='cuda:0')\n",
      "Train loss : 3.9189292703356062\n",
      "Val loss : tensor(3.7784, device='cuda:0')\n",
      "Train loss : 3.5216233049120222\n",
      "Val loss : tensor(3.9024, device='cuda:0')\n",
      "Train loss : 3.4636666093553816\n",
      "Val loss : tensor(3.7788, device='cuda:0')\n",
      "Train loss : 3.679075138909476\n",
      "Val loss : tensor(3.9416, device='cuda:0')\n",
      "Train loss : 3.765798943383353\n",
      "Val loss : tensor(3.7384, device='cuda:0')\n",
      "Train loss : 3.8335113865988597\n",
      "Val loss : tensor(3.8138, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "/home/mila/l/leo.gagnon/explicit_implicit_icl/venv/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:177: Found keys that are not in the model state dict but in the checkpoint: ['w_predictor.weight', 'w_predictor.bias']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 3.353935854775565\n",
      "Val loss : tensor(2.3136, device='cuda:0')\n",
      "Train loss : 1.5687673687934875\n",
      "Val loss : tensor(0.7912, device='cuda:0')\n",
      "Train loss : 0.49709790519305636\n",
      "Val loss : tensor(0.2838, device='cuda:0')\n",
      "Train loss : 0.270723500422069\n",
      "Val loss : tensor(0.2029, device='cuda:0')\n",
      "Train loss : 0.14807628840208054\n",
      "Val loss : tensor(0.1374, device='cuda:0')\n",
      "Train loss : 0.09683113119431905\n",
      "Val loss : tensor(0.0833, device='cuda:0')\n",
      "Train loss : 0.08076975015657288\n",
      "Val loss : tensor(0.0599, device='cuda:0')\n",
      "Train loss : 0.04992461603667055\n",
      "Val loss : tensor(0.0350, device='cuda:0')\n",
      "Train loss : 0.03285386652818748\n",
      "Val loss : tensor(0.0270, device='cuda:0')\n",
      "Train loss : 0.024085753464273045\n",
      "Val loss : tensor(0.0233, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 3.213998453957694\n",
      "Val loss : tensor(2.0095, device='cuda:0')\n",
      "Train loss : 1.3852025355611528\n",
      "Val loss : tensor(0.6147, device='cuda:0')\n",
      "Train loss : 0.35411433024065836\n",
      "Val loss : tensor(0.1255, device='cuda:0')\n",
      "Train loss : 0.08807630730526787\n",
      "Val loss : tensor(0.0509, device='cuda:0')\n",
      "Train loss : 0.03985041167054858\n",
      "Val loss : tensor(0.0335, device='cuda:0')\n",
      "Train loss : 0.030730745622089932\n",
      "Val loss : tensor(0.0262, device='cuda:0')\n",
      "Train loss : 0.030964125746062825\n",
      "Val loss : tensor(0.0217, device='cuda:0')\n",
      "Train loss : 0.023663979821971486\n",
      "Val loss : tensor(0.0237, device='cuda:0')\n",
      "Train loss : 0.019314085133373737\n",
      "Val loss : tensor(0.0218, device='cuda:0')\n",
      "Train loss : 0.019389699612345015\n",
      "Val loss : tensor(0.0204, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 3.958805969783238\n",
      "Val loss : tensor(19.6652, device='cuda:0')\n",
      "Train loss : 4.013682195118496\n",
      "Val loss : tensor(17.6033, device='cuda:0')\n",
      "Train loss : 3.828946692602975\n",
      "Val loss : tensor(19.3740, device='cuda:0')\n",
      "Train loss : 3.935387441090175\n",
      "Val loss : tensor(17.7048, device='cuda:0')\n",
      "Train loss : 3.7977961131504605\n",
      "Val loss : tensor(16.7834, device='cuda:0')\n",
      "Train loss : 3.647902079990932\n",
      "Val loss : tensor(18.0866, device='cuda:0')\n",
      "Train loss : 3.705806085041591\n",
      "Val loss : tensor(18.0124, device='cuda:0')\n",
      "Train loss : 3.642932210649763\n",
      "Val loss : tensor(18.2731, device='cuda:0')\n",
      "Train loss : 3.545614617211478\n",
      "Val loss : tensor(17.8491, device='cuda:0')\n",
      "Train loss : 3.7123308181762695\n",
      "Val loss : tensor(19.4399, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 2.980156489780971\n",
      "Val loss : tensor(10.2945, device='cuda:0')\n",
      "Train loss : 1.5150172369820731\n",
      "Val loss : tensor(4.4984, device='cuda:0')\n",
      "Train loss : 0.5487140885421208\n",
      "Val loss : tensor(1.9907, device='cuda:0')\n",
      "Train loss : 0.2968717111008508\n",
      "Val loss : tensor(1.1654, device='cuda:0')\n",
      "Train loss : 0.1644017579300063\n",
      "Val loss : tensor(1.0068, device='cuda:0')\n",
      "Train loss : 0.10467793260301862\n",
      "Val loss : tensor(0.7604, device='cuda:0')\n",
      "Train loss : 0.06545557560665267\n",
      "Val loss : tensor(0.5530, device='cuda:0')\n",
      "Train loss : 0.040172119225774496\n",
      "Val loss : tensor(0.6879, device='cuda:0')\n",
      "Train loss : 0.03454030491411686\n",
      "Val loss : tensor(0.5391, device='cuda:0')\n",
      "Train loss : 0.025990590187055723\n",
      "Val loss : tensor(0.4927, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss : 2.603308234895979\n",
      "Val loss : tensor(9.2331, device='cuda:0')\n",
      "Train loss : 1.1734027777399336\n",
      "Val loss : tensor(2.9120, device='cuda:0')\n",
      "Train loss : 0.2634147820728166\n",
      "Val loss : tensor(0.8750, device='cuda:0')\n",
      "Train loss : 0.07445224480969566\n",
      "Val loss : tensor(0.4984, device='cuda:0')\n",
      "Train loss : 0.037031687263931544\n",
      "Val loss : tensor(0.3702, device='cuda:0')\n",
      "Train loss : 0.0340986294405801\n",
      "Val loss : tensor(0.4231, device='cuda:0')\n",
      "Train loss : 0.028618727943726947\n",
      "Val loss : tensor(0.3366, device='cuda:0')\n",
      "Train loss : 0.02741645516029426\n",
      "Val loss : tensor(0.2522, device='cuda:0')\n",
      "Train loss : 0.02366162756724017\n",
      "Val loss : tensor(0.3373, device='cuda:0')\n",
      "Train loss : 0.02618378959596157\n",
      "Val loss : tensor(0.3358, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i, v in enumerate([\"iid\", \"wide\"]):\n",
    "    for j, e in enumerate([\"implicit\", \"explicit-transformer\", \"explicit-mlp\"]):\n",
    "        accs[i, j] = val_intervention_acc(v, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.melt(\n",
    "    pd.DataFrame(accs).reset_index(),\n",
    "    id_vars=\"index\",\n",
    "    var_name=\"Model\",\n",
    "    value_name=\"value\",\n",
    ")\n",
    "data.rename(columns={\"index\": \"OOD style\"}, inplace=True)\n",
    "data.rename(columns={\"value\": \"Counterfactual MSE\"}, inplace=True)\n",
    "\n",
    "data['Model'] = data['Model'].map({0: 'Implicit', 1: 'Explicit Transformer', 2: 'Explicit MLP'})\n",
    "data['OOD style'] = data['OOD style'].map({0: 'IID', 1: 'OOD',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style for making nice-looking paper plots with page-scale figure size units\n",
    "sns.set_theme(\n",
    "    style=\"ticks\",\n",
    "    context=\"paper\",\n",
    "    rc={\n",
    "        \"font.size\": 5,\n",
    "        \"axes.titlesize\": 6,\n",
    "        \"axes.labelsize\": 6,\n",
    "        \"axes.labelpad\": 2,\n",
    "        \"xtick.labelsize\": 4.5,\n",
    "        \"ytick.labelsize\": 4.5,\n",
    "        \"legend.title_fontsize\": 4.5,\n",
    "        \"legend.fontsize\": 4.5,\n",
    "        \"legend.markerscale\": 0.5,\n",
    "        \"axes.spines.top\": False,\n",
    "        \"axes.spines.right\": False,\n",
    "        \"axes.linewidth\": 0.4,\n",
    "        \"xtick.major.width\": 0.4,\n",
    "        \"ytick.major.width\": 0.4,\n",
    "        \"xtick.major.size\": 2.5,\n",
    "        \"ytick.major.size\": 2.5,\n",
    "        \"xtick.minor.size\": 1.5,\n",
    "        \"ytick.minor.size\": 1.5,\n",
    "        \"xtick.minor.width\": 0.2,\n",
    "        \"ytick.minor.width\": 0.2,\n",
    "        \"figure.constrained_layout.use\": True,\n",
    "        \"figure.dpi\": 200,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/l/leo.gagnon/explicit_implicit_icl/venv/lib/python3.10/site-packages/seaborn/_base.py:949: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/home/mila/l/leo.gagnon/explicit_implicit_icl/venv/lib/python3.10/site-packages/seaborn/_base.py:949: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n",
      "/home/mila/l/leo.gagnon/explicit_implicit_icl/venv/lib/python3.10/site-packages/seaborn/_base.py:949: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  data_subset = grouped_data.get_group(pd_key)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 10.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x220 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "default_model_colours = {\n",
    "    \"implicit\": sns.color_palette()[7],\n",
    "    \"explicit-transformer\": sns.color_palette()[0],\n",
    "    \"explicit-mlp\": sns.color_palette()[1],\n",
    "    \"explicit-aux-transformer\": sns.color_palette()[4],\n",
    "    \"explicit-known\": sns.color_palette()[2],\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2, 1.1))\n",
    "\n",
    "sns.barplot(\n",
    "    data=data,\n",
    "    ax=ax,\n",
    "    x=\"OOD style\",\n",
    "    y=\"Counterfactual MSE\",\n",
    "    hue=\"Model\",\n",
    "    hue_order=[\"Implicit\", \"Explicit Transformer\", \"Explicit MLP\"],\n",
    "    palette=[\n",
    "        default_model_colours[m]\n",
    "        for m in [\"implicit\", \"explicit-transformer\", \"explicit-mlp\"]\n",
    "    ],\n",
    "    err_kws={\"linewidth\": 1.25},\n",
    ")\n",
    "ax.legend().remove()\n",
    "ax.set(\n",
    "    title=\"Linear regression interventions\",\n",
    "    xlabel=\"Validation data\",\n",
    "    ylabel=r\"Counterfactual MSE ($\\downarrow$)\",\n",
    ")\n",
    "ax.set_ylim([0,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1280x960 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.savefig('xd.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('linreg_intv.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
